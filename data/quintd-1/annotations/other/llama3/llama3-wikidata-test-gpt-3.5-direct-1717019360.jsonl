{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 0, "annotations": [{"reason": "Incorrect fact", "text": "originally in German", "type": 0, "start": 153}, {"reason": "Not checkable", "text": "offers a unique perspective on a rainy day in Venice", "type": 1, "start": 350}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 1, "annotations": [{"reason": "Incorrect fact", "text": "00 time zone", "type": 0, "start": 360}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 2, "annotations": [{"reason": "The fact in the text contradicts the data.", "text": "historical country", "type": 0, "start": 19}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 3, "annotations": [{"reason": "Other", "text": "Arthur Dignam", "type": 3, "start": 130}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 4, "annotations": [{"reason": "Incorrect fact", "text": "Yugoslavia", "type": 0, "start": 29}, {"reason": "Not checkable", "text": "Croatian", "type": 1, "start": 110}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 5, "annotations": [{"reason": "Incorrect fact", "text": "Afghanistan is a country that is a member of the Organisation for the Prohibition of Chemical Weapons.", "type": 0, "start": 0}, {"reason": "Not checkable", "text": "It is governed by the National Assembly of Afghanistan", "type": 1, "start": 103}, {"reason": "Incorrect fact", "text": "The country is home to the ethnic group Hazaras and the language Southern Uzbek is used there.", "type": 0, "start": 230}, {"reason": "Not checkable", "text": "Afghanistan contains the administrative territorial entities of Paktika and Nangarhar,", "type": 1, "start": 325}, {"reason": "Incorrect fact", "text": "and its lowest point is Amu Darya.", "type": 0, "start": 412}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 6, "annotations": [{"reason": "Incorrect fact", "text": "Xianyang", "type": 0, "start": 153}, {"reason": "Not checkable", "text": "Asia", "type": 1, "start": 203}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 7, "annotations": [{"reason": "Incorrect fact", "text": "Moroni", "type": 0, "start": 54}, {"reason": "Not checkable", "text": "based in Moroni", "type": 1, "start": 45}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 8, "annotations": [{"reason": "Incorrect fact", "text": "men's basketball class", "type": 0, "start": 208}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 9, "annotations": [{"reason": "The fact in the text contradicts the data.", "text": "It is categorized as a topic under Gandhara", "type": 0, "start": 194}, {"reason": "The fact in the text cannot be checked in the data.", "text": "known for its significance in ancient history", "type": 1, "start": 245}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 10, "annotations": [{"reason": "Incorrect fact", "text": "based in", "type": 0, "start": 37}, {"reason": "Not checkable", "text": "is a business", "type": 1, "start": 23}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 11, "annotations": [{"reason": "Incorrect fact", "text": "He was born in Ghazni and is currently serving as a Member of the House of the People.", "type": 0, "start": 60}, {"reason": "Not checkable", "text": "Niyaz Mohammad Amiri is a male politician from Afghanistan.", "type": 1, "start": 0}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 12, "annotations": [{"reason": "Incorrect fact", "text": "colorful cinematography", "type": 0, "start": 56}, {"reason": "Not checkable", "text": "renowned actors", "type": 1, "start": 100}, {"reason": "Other", "text": "known for its colorful cinematography", "type": 3, "start": 42}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 13, "annotations": [{"reason": "Incorrect fact", "text": "Carlsbad", "type": 0, "start": 66}, {"reason": "Not checkable", "text": "biotechnology and pharmaceutical industry", "type": 1, "start": 130}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 14, "annotations": [{"reason": "Incorrect fact", "text": "It is a French film.", "type": 0, "start": 204}, {"reason": "Not checkable", "text": "It is a French film.", "type": 1, "start": 204}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 15, "annotations": [{"reason": "Incorrect fact", "text": "color film", "type": 0, "start": 21}, {"reason": "Not checkable", "text": "narrative also taking place in Italy", "type": 1, "start": 255}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 16, "annotations": [{"reason": "Incorrect fact", "text": "As a male athlete", "type": 0, "start": 164}, {"reason": "Not checkable", "text": "Vincent Vaughan has made a name for himself in the Gaelic football community.", "type": 1, "start": 183}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 17, "annotations": [{"reason": "Incorrect fact", "text": "It is a notable instance of Indian cinema", "type": 0, "start": 71}, {"reason": "Not checkable", "text": "thrilling and suspenseful genre", "type": 1, "start": 128}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 18, "annotations": [{"reason": "Incorrect fact", "text": "participated", "type": 0, "start": 28}, {"reason": "Not checkable", "text": "program", "type": 1, "start": 73}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 19, "annotations": [{"reason": "Incorrect fact", "text": "monarchy", "type": 0, "start": 112}, {"reason": "Not checkable", "text": "Tunis", "type": 1, "start": 138}, {"reason": "Misleading", "text": "Northern Berber languages were also used", "type": 2, "start": 233}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 20, "annotations": [{"reason": "Incorrect fact", "text": "female", "type": 0, "start": 25}, {"reason": "Not checkable", "text": "Her given name is Emma.", "type": 1, "start": 39}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 21, "annotations": [{"reason": "Incorrect fact", "text": "France", "type": 0, "start": 44}, {"reason": "Not checkable", "text": "Le Coteau", "type": 1, "start": 85}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 22, "annotations": [{"reason": "Incorrect fact", "text": "female", "type": 0, "start": 23}, {"reason": "Not checkable", "text": "human", "type": 1, "start": 30}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 23, "annotations": [{"reason": "The fact in the text contradicts the data.", "text": "It is categorized under the main topic of the Fourth Dynasty of Egypt.", "type": 0, "start": 61}, {"reason": "The text does not provide any new information that can be checked against the data.", "text": "It is categorized under the main topic of the Fourth Dynasty of Egypt.", "type": 1, "start": 61}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 24, "annotations": [{"reason": "Incorrect fact", "text": "British Raj era", "type": 0, "start": 54}, {"reason": "Not checkable", "text": "Directed by Naresh Mitra and Sisir Bhaduri", "type": 1, "start": 71}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 25, "annotations": [{"reason": "Incorrect fact", "text": "Germany", "type": 0, "start": 47}, {"reason": "Not checkable", "text": "with its headquarters located in Gauting.", "type": 1, "start": 56}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 26, "annotations": [{"reason": "Incorrect fact", "text": "Macedonian", "type": 0, "start": 326}, {"reason": "Incorrect fact", "text": "Serbo-Croatian", "type": 0, "start": 297}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 27, "annotations": [{"reason": "Incorrect fact", "text": "from Germany", "type": 0, "start": 54}, {"reason": "Not checkable", "text": "classified as a silent film", "type": 1, "start": 173}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 28, "annotations": [{"reason": "Not checkable", "text": "United Kingdom", "type": 1, "start": 131}, {"reason": "Incorrect fact", "text": "Sandwell", "type": 0, "start": 121}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 29, "annotations": [{"reason": "Incorrect fact", "text": "headquartered", "type": 0, "start": 22}, {"reason": "Not checkable", "text": "is a business", "type": 1, "start": 8}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 30, "annotations": [{"reason": "Incorrect fact", "text": "followed Interwar Lithuania", "type": 0, "start": 120}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 31, "annotations": [{"reason": "Incorrect fact", "text": "Samhan", "type": 0, "start": 88}, {"reason": "Not checkable", "text": "consisted of two parts", "type": 1, "start": 99}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 32, "annotations": [{"reason": "Incorrect fact", "text": "based in Kaplice", "type": 0, "start": 69}, {"reason": "Not checkable", "text": "production and distribution of pallets, crates, and wooden packaging", "type": 1, "start": 202}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 33, "annotations": [{"reason": "Incorrect fact", "text": "hereditary monarchy form of government", "type": 0, "start": 42}, {"reason": "Not checkable", "text": "Pamplona", "type": 1, "start": 102}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 34, "annotations": [{"reason": "Incorrect fact", "text": "from South Africa", "type": 0, "start": 66}, {"reason": "Not checkable", "text": "considered a lost film", "type": 1, "start": 184}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 35, "annotations": [{"reason": "Incorrect fact", "text": "Icelandic association football player known for his role as a forward.", "type": 0, "start": 26}, {"reason": "Not checkable", "text": "showcasing his talent at both the domestic and international levels.", "type": 1, "start": 369}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 36, "annotations": [{"reason": "Incorrect fact", "text": "from the United States of America", "type": 0, "start": 40}, {"reason": "Not checkable", "text": "presented in color", "type": 1, "start": 94}, {"reason": "Misleading", "text": "set in Utah", "type": 2, "start": 157}, {"reason": "Incorrect fact", "text": "English", "type": 0, "start": 211}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 37, "annotations": [{"reason": "Incorrect fact", "text": "", "type": 0, "start": 0}, {"reason": "Not checkable", "text": "produced by Shint\u014dh\u014d", "type": 1, "start": 50}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 38, "annotations": [{"reason": "Incorrect fact", "text": "Italy", "type": 0, "start": 45}, {"reason": "Not checkable", "text": "Guidonia Montecelio", "type": 1, "start": 85}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 39, "annotations": [{"reason": "Incorrect fact", "text": "also called Baban", "type": 0, "start": 69}, {"reason": "Not checkable", "text": "historical country", "type": 1, "start": 12}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 40, "annotations": [{"reason": "Incorrect fact", "text": "", "type": 0, "start": 0}, {"reason": "Not checkable", "text": "Little Zab", "type": 1, "start": 187}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 41, "annotations": [{"reason": "Incorrect fact", "text": "United States of America", "type": 0, "start": 54}, {"reason": "Not checkable", "text": "has its own discography known as the CBS Associated Records catalog", "type": 1, "start": 124}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 42, "annotations": [{"reason": "Incorrect fact: The firm is named after Steve Tompkins and Graham Haworth", "text": "named after Steve Tompkins", "type": 0, "start": 96}, {"reason": "Not checkable: The text does not specify which of the two individuals is named after", "text": "named after Steve Tompkins and Graham Haworth", "type": 1, "start": 96}, {"reason": "Incorrect fact: The firm received the Stirling Prize", "text": "receiving the Stirling Prize", "type": 0, "start": 161}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 43, "annotations": [{"reason": "Incorrect fact", "text": "Argentine origin", "type": 0, "start": 36}, {"reason": "Not checkable", "text": "color aesthetics", "type": 1, "start": 123}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 44, "annotations": [{"reason": "Incorrect fact", "text": "princely state of the British Raj", "type": 0, "start": 44}, {"reason": "Not checkable", "text": "Small Brockhaus and Efron Encyclopedic Dictionary", "type": 1, "start": 234}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 45, "annotations": [{"reason": "Incorrect fact", "text": "from Iran", "type": 0, "start": 35}, {"reason": "Not checkable", "text": "He is known for his occupation as a grass skiing competitor", "type": 1, "start": 46}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 46, "annotations": [{"reason": "Incorrect fact", "text": "NRHP contributing property", "type": 0, "start": 166}, {"reason": "Not checkable", "text": "listed on the National Register of Historic Places", "type": 1, "start": 205}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 47, "annotations": [{"reason": "Incorrect fact", "text": "public-law institution", "type": 0, "start": 85}, {"reason": "Not checkable", "text": "various banking and financial services", "type": 1, "start": 267}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 48, "annotations": [{"reason": "Incorrect fact", "text": "United States of America", "type": 0, "start": 69}, {"reason": "Not checkable", "text": "New York", "type": 1, "start": 222}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 49, "annotations": [{"reason": "Incorrect fact", "text": "based", "type": 0, "start": 28}, {"reason": "Not checkable", "text": "operating within", "type": 1, "start": 67}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 50, "annotations": [{"reason": "Incorrect fact", "text": "primarily in English", "type": 0, "start": 238}, {"reason": "Not checkable", "text": "revolves around", "type": 1, "start": 263}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 51, "annotations": [{"reason": "Incorrect fact", "text": "He was born in Wanzleben-B\u00f6rde and passed away in Leipzig.", "type": 0, "start": 48}, {"reason": "Not checkable", "text": "Reinhold Schultz was a male judge from Germany.", "type": 1, "start": 0}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 52, "annotations": [{"reason": "Incorrect fact", "text": "New-York Gazette is a newspaper based in Manhattan.", "type": 0, "start": 4}, {"reason": "The data mentions headquarters location as Manhattan, but the text states it is 'based in'", "text": "based in", "type": 2, "start": 36}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 53, "annotations": [{"reason": "Incorrect fact", "text": "headquarters location", "type": 0, "start": 204}, {"reason": "Not checkable", "text": "serves as a prominent source of news and information", "type": 1, "start": 140}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 54, "annotations": [{"reason": "Incorrect fact", "text": "Latvian Soviet Socialist Republic", "type": 0, "start": 106}, {"reason": "Not checkable", "text": "Russian", "type": 1, "start": 242}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 55, "annotations": [{"reason": "Incorrect fact", "text": "Polish-Lithuanian Commonwealth", "type": 0, "start": 172}, {"reason": "Not checkable", "text": "member of the Bogatkowie herbu Pomian family", "type": 1, "start": 102}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 56, "annotations": [{"reason": "Incorrect fact", "text": "Kingdom of Italy", "type": 0, "start": 58}, {"reason": "Not checkable", "text": "Messina", "type": 1, "start": 91}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 57, "annotations": [{"reason": "Incorrect fact", "text": "Munich", "type": 0, "start": 76}, {"reason": "Not checkable", "text": "based in Munich, Germany", "type": 1, "start": 67}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 58, "annotations": [{"reason": "The fact in the text contradicts the data.", "text": "Armenian Soviet Encyclopedia", "type": 0, "start": 61}, {"reason": "The fact in the text cannot be checked in the data.", "text": "subject of a Wikimedia list article", "type": 1, "start": 109}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 59, "annotations": [{"reason": "Incorrect fact", "text": "located", "type": 0, "start": 122}, {"reason": "Not checkable", "text": "spoken", "type": 1, "start": 187}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 60, "annotations": [{"reason": "Incorrect fact", "text": "vibrant color scheme", "type": 0, "start": 238}, {"reason": "Not checkable", "text": "captivating storyline", "type": 1, "start": 212}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 61, "annotations": [{"reason": "Incorrect fact", "text": "Desperado", "type": 0, "start": 8}, {"reason": "Not checkable", "text": "ensemble cast", "type": 1, "start": 36}, {"reason": "Incorrect fact", "text": "Chrispin Martin", "type": 0, "start": 116}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 62, "annotations": [{"reason": "Incorrect fact", "text": "Muslim-ruled state", "type": 0, "start": 120}, {"reason": "Not checkable", "text": "Iberian Peninsula", "type": 1, "start": 146}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 63, "annotations": [{"reason": "Incorrect fact", "text": "born in New Bern", "type": 0, "start": 73}, {"reason": "Not checkable", "text": "from the United States of America", "type": 1, "start": 38}, {"reason": "Misleading", "text": "She passed away in Washington, D.C. due to pneumonia", "type": 2, "start": 204}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 64, "annotations": [{"reason": "Incorrect fact", "text": "male", "type": 0, "start": 27}, {"reason": "Not checkable", "text": "is a", "type": 1, "start": 22}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 65, "annotations": [{"reason": "Incorrect fact", "text": "It is in the German language", "type": 0, "start": 175}, {"reason": "Not checkable", "text": "was shot by the director of photography, Gernot Roll", "type": 1, "start": 208}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 66, "annotations": [{"reason": "Incorrect fact", "text": "based in Rozzano", "type": 0, "start": 51}, {"reason": "Not checkable", "text": "producing automobiles", "type": 1, "start": 151}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 67, "annotations": [{"reason": "Incorrect fact", "text": "black-and-white", "type": 0, "start": 20}, {"reason": "Not checkable", "text": "United States of America", "type": 1, "start": 57}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 68, "annotations": [{"reason": "Incorrect fact", "text": "public domain", "type": 0, "start": 221}, {"reason": "Not checkable", "text": "available for public viewing and distribution", "type": 1, "start": 246}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 69, "annotations": [{"reason": "Incorrect fact", "text": "United States of America", "type": 0, "start": 62}, {"reason": "Not checkable", "text": "Wesleyan University", "type": 1, "start": 107}, {"reason": "Other", "text": "The Pilgrim's Progress", "type": 3, "start": 163}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 70, "annotations": [{"reason": "Incorrect fact", "text": "from France", "type": 0, "start": 60}, {"reason": "Not checkable", "text": "public use", "type": 1, "start": 152}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 71, "annotations": [{"reason": "Incorrect fact", "text": "specializing in beekeeping", "type": 0, "start": 106}, {"reason": "Not checkable", "text": "based in Lublin", "type": 1, "start": 56}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 72, "annotations": [{"reason": "The fact in the text contradicts the data.", "text": "male", "type": 0, "start": 20}, {"reason": "No error found.", "text": "", "type": 3, "start": 24}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 73, "annotations": [{"reason": "The fact in the text contradicts the data.", "text": "and a princely state of the British Raj", "type": 0, "start": 36}, {"reason": "Not checkable: The fact in the text cannot be checked in the data.", "text": "located in Asia", "type": 1, "start": 76}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 74, "annotations": [{"reason": "Incorrect fact", "text": "United States of Belgium", "type": 0, "start": 4}, {"reason": "The data only mentions 'Belgium', not 'United States'", "text": "", "type": 1, "start": 28}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 75, "annotations": [{"reason": "Incorrect fact", "text": "associated with", "type": 0, "start": 47}, {"reason": "Not checkable", "text": "actively involved in research activities.", "type": 1, "start": 133}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 76, "annotations": [{"reason": "Incorrect fact", "text": "Casablanca", "type": 0, "start": 34}, {"reason": "Not checkable", "text": "based in", "type": 1, "start": 25}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 77, "annotations": [{"reason": "Incorrect fact", "text": "Bangladesh Nationalist Party", "type": 0, "start": 51}, {"reason": "Not checkable", "text": "male", "type": 1, "start": 17}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 78, "annotations": [{"reason": "Incorrect fact", "text": "specifically in the Wakayama Prefecture", "type": 0, "start": 64}, {"reason": "Not checkable", "text": "Nishimuro District, and Shirahama area within the Kansai region", "type": 1, "start": 105}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 79, "annotations": [{"reason": "Not checkable", "text": "monarchy", "type": 1, "start": 104}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 80, "annotations": [{"reason": "Incorrect fact", "text": "based in Hobart.", "type": 0, "start": 44}, {"reason": "Not checkable", "text": "", "type": 1, "start": 60}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 81, "annotations": [{"reason": "Not checkable", "text": "Hohenstein", "type": 1, "start": 70}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 82, "annotations": [{"reason": "Not checkable", "text": "played a significant role in the region's history", "type": 1, "start": 361}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 83, "annotations": [{"reason": "Incorrect fact", "text": "Mosfilm", "type": 0, "start": 51}, {"reason": "Not checkable", "text": "detective fiction", "type": 1, "start": 194}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 84, "annotations": [{"reason": "Incorrect fact", "text": "Lithuanian", "type": 0, "start": 23}, {"reason": "Not checkable", "text": "", "type": 1, "start": 33}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 85, "annotations": [{"reason": "Incorrect fact", "text": "based in Spain", "type": 0, "start": 59}, {"reason": "Not checkable", "text": "operating as a key player", "type": 1, "start": 130}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 86, "annotations": [{"reason": "Incorrect fact", "text": "It operates as an Aktiengesellschaft", "type": 0, "start": 68}, {"reason": "Not checkable", "text": "which is a legal form of a joint-stock company in Switzerland.", "type": 1, "start": 106}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 87, "annotations": [{"reason": "The fact in the text cannot be checked in the data.", "text": "The sultanate is no longer in existence.", "type": 1, "start": 138}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 88, "annotations": [{"reason": "Incorrect fact", "text": "documentary and is classified as a film.", "type": 0, "start": 105}, {"reason": "Not checkable", "text": "falls under the genre of documentary", "type": 1, "start": 80}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 89, "annotations": [{"reason": "The fact in the text contradicts the data.", "text": "broadsheet", "type": 0, "start": 33}, {"reason": "The fact in the text is not checkable in the data.", "text": "newspaper", "type": 1, "start": 44}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 90, "annotations": [{"reason": "Incorrect fact", "text": "female", "type": 0, "start": 28}, {"reason": "Not checkable", "text": "", "type": 1, "start": 34}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 91, "annotations": [{"reason": "Incorrect fact", "text": "serving as directors/managers", "type": 0, "start": 90}, {"reason": "Not checkable", "text": "The company is known for its contributions to the publishing industry.", "type": 1, "start": 121}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 92, "annotations": [{"reason": "The fact in the text contradicts the data.", "text": "World Heritage Site", "type": 0, "start": 112}, {"reason": "The fact in the text cannot be checked in the data.", "text": "showcasing its significance", "type": 1, "start": 176}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 93, "annotations": [{"reason": "The fact contradicts the data", "text": "female", "type": 0, "start": 29}, {"reason": "Not checkable", "text": "is a female human", "type": 1, "start": 24}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 94, "annotations": [{"reason": "Incorrect fact", "text": "He is a human being named Antonio.", "type": 0, "start": 113}, {"reason": "Not checkable", "text": "named Antonio.", "type": 1, "start": 133}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 95, "annotations": [{"reason": "Incorrect fact", "text": "Australia national rugby union team", "type": 0, "start": 137}, {"reason": "Incorrect fact", "text": "Australia A national rugby union team", "type": 0, "start": 188}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 96, "annotations": [{"reason": "Incorrect fact", "text": "headquartered", "type": 0, "start": 29}, {"reason": "Not checkable", "text": "", "type": 1, "start": 42}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 97, "annotations": [{"reason": "Incorrect fact", "text": "Category II", "type": 0, "start": 34}, {"reason": "Incorrect fact", "text": "Joanna Krupa", "type": 0, "start": 140}, {"reason": "Incorrect fact", "text": "Jennifer Coolidge", "type": 0, "start": 154}, {"reason": "Incorrect fact", "text": "Matthew Davis", "type": 0, "start": 173}, {"reason": "Incorrect fact", "text": "Selma Blair", "type": 0, "start": 192}, {"reason": "Not checkable", "text": "Santa Monica", "type": 1, "start": 222}, {"reason": "Other", "text": "produced by Marc E. Platt, with the screenplay written by Kirsten Smith.", "type": 3, "start": 239}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 98, "annotations": [{"reason": "Incorrect fact", "text": "La Marseillaise", "type": 0, "start": 224}, {"reason": "Not checkable", "text": "Naissance au Cameroun fran\u00e7ais", "type": 1, "start": 400}, {"reason": "Other", "text": "French Cameroons was a historical country that was under the authority of the League of Nations and later the United Nations Organisation as a trust territory.", "type": 3, "start": 0}, {"reason": "Incorrect fact", "text": "the French franc, which was later replaced by the CFA franc", "type": 0, "start": 283}]}
{"annotator_id": "llama3", "dataset": "wikidata", "model": "gpt-3.5", "setup": "direct", "split": "test", "table_idx": 99, "annotations": [{"reason": "Incorrect fact", "text": "directed by Margarita Sol\u00e1", "type": 0, "start": 69}, {"reason": "Not checkable", "text": "The original language of the film is Spanish.", "type": 1, "start": 183}]}
